---
title: "IYS-Trawl-Integration"
author: "Tim van der Stap"
date: '2022-06-21'
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(here)
library(lubridate)
library(obistools)
library(chron)
library(janitor)
library(rerddap)
knitr::opts_chunk$set(echo = TRUE)
```

For date integration, first download the processed data. For the 2022 data, this will be included in the IYS-data-template. From public repositories, we can download straight from the repository:  

```{r download IYS data template files}
download.file("https://github.com/international-year-of-the-salmon/2022-NW-Data-Template/blob/main/IYS2022_NW_Data.xlsx?raw=true", here::here("input_datasets",  "IYS2022_NW_Data.xlsx"), quiet = TRUE, mode = "wb")

download.file("https://github.com/international-year-of-the-salmon/2022-TINRO-Data-Template/blob/main/IYS2022_TINRO.xlsx?raw=true", here::here("input_datasets", "IYS2022_TINRO_Data.xlsx"), quiet = TRUE, mode = "wb")

download.file("https://github.com/international-year-of-the-salmon/2022-shimada-data-template/blob/main/IYS2022_Shimada_Data_template.xlsx?raw=true", here::here("input_datasets", "IYS2022_Shimada_Data.xlsx"), quiet = TRUE, mode = "wb")

download.file("https://github.com/international-year-of-the-salmon/2022-Franklin-Data-Template/blob/main/IYS_2022_FRANKLIN.xlsx?raw=true", here::here("input_datasets", "IYS2022_Franklin_Data.xlsx"), quiet = TRUE, mode = "wb")

```

From private repositories, use the following chunk of code, making sure to change the github_link to point to the correct private repository.

# Trawl Data

## Event Data 

Now that we have the latest versions of the trawl data downloaded, we can read them in:

```{r event data, eval = FALSE}

NW_event <- read_excel(here("input_datasets", "IYS2022_NW_Data.xlsx"), 
                       sheet = "Sampling_Event_Info") %>%
  filter(Event_Type == "CanTrawl") 

TINRO_event <- read_excel(here("input_datasets", "IYS2022_TINRO_Data.xlsx"), 
                          sheet = "4. SAMPLING EVENT INFO") %>%
  filter(Event_Type %in% c("Trawl", "CTD"))

Shimada_event <- read_excel(here("input_datasets", "IYS2022_Shimada_Data.xlsx"),
                            sheet = "4. SAMPLING EVENT INFO") %>%
  filter(Event_Type %in% c("Trawl", "CTD"))

Franklin_event <- read_excel(here("input_datasets", "IYS2022_Franklin_Data.xlsx"),
                             sheet = "3. SAMPLING EVENT INFO") |> 
  filter(Event_Type %in% c("Trawl", "CTD_Rosette"))

# Need to download this file manually from 2019 Trawl git repo
GoA2019_event <- read_excel(here("input_datasets",
                                 "JuvSalmon_2019-01_catch.v20.12_FINAL_SUBMITTED (2).xlsx"),
                            sheet = "BRIDGE_LOG_FINAL")

# Need to download this file manually from 2020 Trawl git repo
GoA2020_event <- read_excel(here("input_datasets",
                                 "JuvSalmon_2020-01_Catch_v2021.1C_FINAL SUBMIT_jan18_2021 (2).xlsx"), 
                            sheet = "BRIDGE_LOG_FINAL")
```

Compare event tables from the various vessel sampling events:

```{r event comparison, eval = FALSE}
# Check for differences in column header names and class between those data frames:
janitor::compare_df_cols(NW_event, TINRO_event, Shimada_event, Franklin_event)
```

Looks like we have to do a little bit of cleaning before we join the data frames!

```{r Shimada event cleaning, eval = FALSE}
Shimada_event <- Shimada_event %>%
  mutate(Time_Start = as.POSIXct(Time_Start, format = "%H:%M:%S") %>% format("%H:%M:%S"),
         Time_End = as.POSIXct(Time_End, format = "%H:%M:%S") %>% format("%H:%M:%S"),
         Time_Zone_Code = "UTC",
         Station_Event_ID = ifelse(Event_Type == "CTD", paste0(Station_Event_ID, Maximum_Sampling_Depth_Meters), Station_Event_ID)) %>%
  dplyr::rename(Bottom_Depth_Meters = `Bottom_Depth*_Meters`) |> 
  rename_with(tolower)

# Change station class to character:
Shimada_event$station <- as.character(Shimada_event$station)
```

For NW data:

```{r NW event cleaning, eval = FALSE}
NW_event <- NW_event %>%
  dplyr::rename(Maximum_Sampling_Depth_Meters = Maximum_Sampling_Depth,
                Minimum_Sampling_Depth_Meters = Minimum_Sampling_Depth,
                Cruise_name = Cruise_Name) %>% # remember: rename(new = old)
  mutate(Time_Zone_Code = "UTC")

# Change class where needed:
NW_event$Month <- as.numeric(NW_event$Month)
NW_event$Day <- as.numeric(NW_event$Day)
NW_event$Time_End <- as.POSIXct(NW_event$Time_End, format = "%H:%M:%S") %>% format("%H:%M:%S")
NW_event$Time_Start <- as.POSIXct(NW_event$Time_Start, format = "%H:%M:%S") %>% format("%H:%M:%S")

# NW Cruise_name and Station Event ID have to be slightly altered:
NW_event$Cruise_name <- str_replace(NW_event$Cruise_name, "NW2201", "IYS2022")
NW_event$Station_Event_ID <- str_replace(NW_event$Station_Event_ID, "NW2201", "IYS2022")

NW_event <- NW_event |> 
  rename_with(tolower)

# Change station class to character:
NW_event$station <- as.character(NW_event$station)

# TODO: Additionally, you'll notice that there are three duplicate Station_Event_IDs. Likely - though needs confirmation - all the catch and specimen data comes from the trawl events that were ~60 minutes in length. Therefore, events that lasted 15 minutes will likely have to be filtered out. 
# NW_event <- NW_event %>% filter(Sampling_Duration_Minutes != "15") # Confirm with Jim & Murphy!
```

And for TINRO data:

```{r TINRO event cleaning, eval = FALSE}
# Trawl data is collected in GMT+12:00. So we have to subtract 12 hours from the Time_Start and Time_End to get to UTC. Additionally, we have to make sure this is then accurately reflected in the sampling **day** as well!
hrs <- 12 * 60 * 60

TINRO_event$date <- as.Date(paste(TINRO_event$Year, TINRO_event$Month, TINRO_event$Day, sep = "-"))
TINRO_event$Time_Start <- as.POSIXct(TINRO_event$Time_Start, format = "%H:%M:%S")
TINRO_event$Time_Start <- as.POSIXct(TINRO_event$Time_Start, format = "%H:%M:%S") %>% format("%H:%M:%S")

TINRO_event <- TINRO_event %>%
  mutate(eventDate_start = paste(date, Time_Start))
TINRO_event <- TINRO_event %>%
  mutate(eventDate_start = as.POSIXlt(TINRO_event$eventDate_start))
TINRO_event$eventDate_start$hour = TINRO_event$eventDate_start$hour-12

TINRO_event$Year <- as.numeric(format(as.Date(TINRO_event$eventDate_start), "%Y"))
TINRO_event$Month <- as.numeric(format(as.Date(TINRO_event$eventDate_start), "%m"))
TINRO_event$Day <- as.numeric(format(as.Date(TINRO_event$eventDate_start), "%d"))

# Reformat time, and transform to UTC:
TINRO_event$Time_End <- as.POSIXct(TINRO_event$Time_End, format = "%H:%M:%S")
TINRO_event$Time_End <- TINRO_event$Time_End - hrs
TINRO_event$Time_End <- as.POSIXct(TINRO_event$Time_End, format = "%H:%M:%S") %>% format("%H:%M:%S") 

TINRO_event$Time_Start <- as.POSIXct(TINRO_event$Time_Start, format = "%H:%M:%S")
TINRO_event$Time_Start <- TINRO_event$Time_Start - hrs
TINRO_event$Time_Start <- as.POSIXct(TINRO_event$Time_Start, format = "%H:%M:%S") %>% format("%H:%M:%S")# Change class and time to UTC for integration

# Sampling duration minutes has to be reformatted.
TINRO_event$Sampling_Duration_Minutes <- 60 * 24 * as.numeric(chron::times(TINRO_event$Sampling_Duration_Minutes)) 
TINRO_event$Sampling_Duration_Minutes <- round(TINRO_event$Sampling_Duration_Minutes, digits = 2)

# Change Time_Zone_Code to state that the Time_Start and Time_End now reflects UTC:
TINRO_event$Time_Zone_Code <- "UTC"

# Change station class to character:
TINRO_event$station <- as.character(TINRO_event$station)

# Remove temporary columns:
TINRO_event <- TINRO_event %>% select(-c(date, eventDate_start)) |> 
  rename_with(tolower)
```

And for Franklin data:

```{r Franklin event cleaning, eval = FALSE}
Franklin_event$Month <- ifelse(Franklin_event$Month == "Feb", "2", "3") %>% as.numeric()

# Change Tow_distance from kilometers per hour to nautical miles:
Franklin_event$Tow_distance[Franklin_event$Tow_distance=="NA"] <- 0
Franklin_event$Tow_distance <- as.numeric(Franklin_event$Tow_distance)
Franklin_event <- Franklin_event %>%
  mutate(tow_distance_nautical_miles = Tow_distance / 1.852)

Franklin_event$tow_distance_nautical_miles <- round(Franklin_event$tow_distance_nautical_miles, digits = 4)

# TODO: If I run the next 4 lines of code at the same time it doesn't work, have to fix:
Franklin_event <- Franklin_event %>%
  mutate(Time_Start_UTC = gsub(".*T", "", Franklin_event$Time_Start_UTC)) %>%
  mutate(Time_End_UTC = gsub(".*T", "", Franklin_event$Time_End_UTC)) %>%
  mutate(Time_Start_UTC = gsub("Z","",Franklin_event$Time_Start_UTC)) %>%
  mutate(Time_End_UTC = gsub("Z", "", Franklin_event$Time_End_UTC))

Franklin_event$Time_End_UTC <- as.POSIXct(Franklin_event$Time_End_UTC, format = "%H:%M:%S")  %>% format("%H:%M:%S")
Franklin_event$Time_Start_UTC <- as.POSIXct(Franklin_event$Time_Start_UTC, format = "%H:%M:%S") %>% format("%H:%M:%S")

# Rename and select columns to integrate:
Franklin_event <- Franklin_event %>%  
  rename_with(tolower) %>%
  dplyr::rename(time_start = time_start_utc,
                time_end = time_end_utc,
                tow_speed_kilometers_per_hour = tow_speed,
                bottom_depth_meters = bottom_depth_start,
                wave_height_meters = wave_height,
                sampling_duration_minutes = sampling_duration)

Franklin_event <- Franklin_event %>%
  mutate(time_zone_code = "UTC",
         wind_direction_degrees = NA,
         wind_direction_kilometers_per_hour = NA,
         swell_height_meters = NA,
         weather_description = NA) %>%
  select(cruise_name, vessel_name_abbr, zone, station, event_type, station_event_id, year, month, day, time_start, time_end,
         sampling_duration_minutes, day_night, time_zone_code, minimum_sampling_depth_meters, maximum_sampling_depth_meters,
         tow_speed_kilometers_per_hour, latitude_start_decdeg, longitude_start_decdeg, latitude_end_decdeg, longitude_end_decdeg,
         bottom_depth_meters, tow_distance_nautical_miles, wave_height_meters, swell_height_meters, weather_description, comments)

# TODO: Rather than select columns to include, remove columns not used.

# TODO: Clean up the following code lines: 
Franklin_event$sampling_duration_minutes <- as.numeric(Franklin_event$sampling_duration_minutes)
Franklin_event$minimum_sampling_depth_meters <- as.numeric(Franklin_event$minimum_sampling_depth_meters)
Franklin_event$maximum_sampling_depth_meters <- as.numeric(Franklin_event$maximum_sampling_depth_meters)
Franklin_event$wave_height_meters <- as.numeric(Franklin_event$wave_height_meters)
```

Clean up the GoA2019 Trawl event data:

```{r GOA2019 event cleaning, eval = FALSE}
GoA2019_event$END_DEPLOYMENT_TIME <- substr(as.POSIXct(sprintf("%04.0f", GoA2019_event$END_DEPLOYMENT_TIME), format = "%H%M"), 12, 16) 
GoA2019_event$BEGIN_RETRIEVAL_TIME <- substr(as.POSIXct(sprintf("%04.0f", GoA2019_event$BEGIN_RETRIEVAL_TIME), format = "%H%M"), 12, 16)

GoA2019_event <- GoA2019_event %>%
  mutate(Cruise_name = "IYS2022",
         Vessel_Name_Abbr = "Kaganovsky",
         Zone = " ",
         Time_Zone_Code = "GMT+12",
         Minimum_Sampling_Depth_Meters = 0) %>%
  dplyr::rename(Station = TOW_NUMBER,
                Event_Type = EVENT_TYPE,
                Time_Start = END_DEPLOYMENT_TIME,
                Time_End = BEGIN_RETRIEVAL_TIME,
                Sampling_Duration_Minutes = TOW_DURATION,
                Day_Night = `Day /Night`,
                Maximum_Sampling_Depth_Meters = MOUTH_OPENING_HEIGHT,
                Latitude_Start_DecDeg = START_LATITUDE_DD,
                Longitude_Start_DecDeg = longitude,
                Latitude_End_DecDeg = END_LATITUDE_DD,
                Longitude_End_DecDeg = END_LONGITUDE_DD,
                Bottom_Depth_Meters = BOTTOM_DEPTH_START_METERS,
                Tow_distance_nautical_miles = DISTANCE_TRAVELLED,
                Tow_speed_kilometers_per_hour = SPEED,
                Wind_Direction_Degrees = WIND_DIRECTION,
                Wind_Speed_kilometers_per_hour = WIND_SPEED,
                Weather_description = WEATHER_COMMENTS, 
                Comments = `COMMENTS TRANSLATED TO ENGLISH`)

GoA2019_event$Year <- as.numeric(format(as.Date(GoA2019_event$EVENT_DATE), "%Y"))
GoA2019_event$Month <- as.numeric(format(as.Date(GoA2019_event$EVENT_DATE), "%m"))
GoA2019_event$Day <- as.numeric(format(as.Date(GoA2019_event$EVENT_DATE), "%d"))

# Change some classes:
GoA2019_event$Zone <- as.numeric(GoA2019_event$Zone)
GoA2019_event$Wind_Direction_Degrees <- as.numeric(GoA2019_event$Wind_Direction_Degrees)
GoA2019_event$Wind_Speed_kilometers_per_hour <- as.numeric(GoA2019_event$Wind_Speed_kilometers_per_hour)

GoA2019_event <- GoA2019_event %>%
  mutate(Sampling_Duration_Minutes = Sampling_Duration_Minutes * 60,
         station_event_id = paste(Cruise_name, Vessel_Name_Abbr, Station, Event_Type, sep = "-"),
         Longitude_End_DecDeg = Longitude_End_DecDeg * -1) %>%
  select(Cruise_name, Vessel_Name_Abbr, Zone, Station, station_event_id, 
         Event_Type, Year, Month, Day, Time_Start, Time_End, Sampling_Duration_Minutes,
         Day_Night, Time_Zone_Code, Minimum_Sampling_Depth_Meters, 
         Maximum_Sampling_Depth_Meters, Tow_speed_kilometers_per_hour, Latitude_Start_DecDeg, 
         Longitude_Start_DecDeg, Latitude_End_DecDeg, Longitude_End_DecDeg, 
         Bottom_Depth_Meters, Tow_distance_nautical_miles,
         Wind_Direction_Degrees, Wind_Speed_kilometers_per_hour, Comments) |> 
  rename_with(tolower)

# Include CTD events
# Create event data for 2019 CTD
IYS_2019_CTD <- read_csv("https://raw.githubusercontent.com/international-year-of-the-salmon/2019-CTD/main/standardized_data/IYS_2019_CTD.csv")

ctd_2019_event <- IYS_2019_CTD |> 
   select(cruise_name:bottom_depth_meters) |> 
  distinct() |> 
  mutate(time_start = as.character(time_start)) |> 
  rename(station_event_id = station_event_ID)

janitor::compare_df_cols(GoA2019_event, ctd_2019_event)

GoA2019_event <- bind_rows(GoA2019_event, ctd_2019_event)
```

```{r GOA2020 event cleaning, eval = FALSE}
#TODO clean 2020 event data


# Create event data for 2020 CTD
#TODO: replace this data file with standardized one sent to ERDDAP (just used this file temporarily to get a complete list of stations for Tetjana)
IYS_2020_CTD <- read_csv("https://github.com/international-year-of-the-salmon/2020-CTD/blob/master/original_data/IYS%202020%20CTD%20-%20Processed%2020200415.csv?raw=true")

#TODO: Add 2020 CTD event data to 2020 GoA Trawl Data

```

Finally, join the data frames into a single sampling event data table: 

```{r IYS2022 all sampling events, eval = FALSE}
#TODO Include 2020 GoA Events
# Check for differences in column header names and class between those two data frames:
janitor::compare_df_cols(NW_event, TINRO_event, Shimada_event, Franklin_event)

# Join the individual event data frames and make all column names :
IYS2022_events <- bind_rows(TINRO_event, NW_event, Shimada_event, Franklin_event) |> 
  mutate(event_date = paste0(year,"-", 
                             ifelse(nchar(month) < 2, 
                                    paste0("0", month), month), "-",
                             ifelse(nchar(day) < 2,
                                    paste0("0", day),day), 
                             "T", time_start, "Z")) |> 
  rename(station_event_ID = station_event_id) |> 
  select(cruise_name:station_event_ID, event_date, year:comments)

# Save event data:
write_csv(IYS2022_events, here("output_datasets", "IYS2022_events.csv"))
```


## Catch Data

Now let's join the overall catch data from these vessels into a specific data frame as well. 

```{r overall catch, eval = FALSE}
NW_catch <- read_excel(here("input_datasets", "IYS2022_NW_Data.xlsx"), sheet = "Catch_Info")
TINRO_catch <- read_excel(here("input_datasets", "IYS2022_TINRO_Data.xlsx"), sheet = "5. CATCH_FINAL INFO")
Shimada_catch <- read_excel(here("input_datasets", "IYS2022_Shimada_Data.xlsx"), sheet = "5. CATCH_FINAL INFO")
Franklin_catch <- read_excel(here("input_datasets", "IYS2022_Franklin_Data.xlsx"), sheet = "4. CATCH_FINAL INFO")

#TODO Include 2019 catch data
GoA2019_catch <- read_excel(here("input_datasets", "JuvSalmon_2019-01_catch.v20.12_FINAL_SUBMITTED (2).xlsx"),
                            sheet = "CATCH_FINAL")
```

Cleaning TINRO catch names:

```{r TINRO catch clean, eval = FALSE}
TINRO_catch <- TINRO_catch %>% rename_with(tolower)
```

Cleaning NW catch column names:

```{r NW catch clean, eval = FALSE}
NW_catch <- NW_catch %>%
  dplyr::rename(Station_Event_ID = `Station Event ID`,
                Catch_ID = `Catch ID`,
                Species_recorded = Species_Recorded,
                Catch_weight = Catch_Weight,
                Catch_count = Catch_Count) %>%
  rename_with(tolower)
```

Cleaning Shimada catch column names to ensure integration:

```{r Shimada catch clean, eval = FALSE}
Shimada_catch <- Shimada_catch %>%
  dplyr::rename(dateIdentified = `dateIdentified (UTC)`) %>%
  rename_with(tolower)
```

Cleaning Franklin catch column names:

```{r Franklin catch clean, eval = FALSE}
Franklin_catch <- Franklin_catch %>% rename_with(tolower)
```

Cleaning GoA2019 catch column names:

```{r GOA2019 catch clean, eval = FALSE}
GoA2019_catch <- GoA2019_catch %>%
  mutate(cruise_name = "IYS2022",
         Vessel_Name_Abbr = "Professor Kaganovskiy",
         Zone = " ",
         Event_Type = "Trawl") %>%
  dplyr::rename(Station = `TOW_NUMBER (number)`,
                common_name = `common name`,
                Catch_weight = `Mass_codend (no expansion)`,
                Catch_count = `CATCH_COUNT (pieces)(**includes Russian expansion for some species)`,
                Lifestage = `age group ( for salmon 5= juv, 4 immature, 3 mature, 0 unknown)`,
                Comments = COMMENTS) %>%
  mutate(Station_Event_ID = paste(cruise_name, Vessel_Name_Abbr, Station, Event_Type, sep = "-"),
         Catch_ID = paste(Station_Event_ID, row_number(), sep = "-"),
         Species_recorded = NA,
         Scientific_Name = paste(genus, species, sep = " "),
         Taxonomic_rank = ifelse(grepl("sp.", GoA2019_catch$species), "genus", "species"),
         Catch_weight_units = "kilograms") %>%
  select(Station_Event_ID, Catch_ID, Species_recorded, Scientific_Name, Taxonomic_rank, Lifestage, common_name, Catch_weight, Catch_weight_units,
         Catch_count, Comments)

```

Compare column names between catch data frames: 

```{r bridgelog, eval = FALSE}
# Check for differences in column header names between those two data frames:
janitor::compare_df_cols(NW_catch, TINRO_catch, Shimada_catch, Franklin_catch)

# Bind rows and save: 
IYS2022_trawl_catch <- bind_rows(TINRO_catch, NW_catch, Shimada_catch, Franklin_catch)
IYS2022_trawl_catch$dateidentified <- as.character(IYS2022_trawl_catch$dateidentified)

# Confirm there are no duplicates in the Catch_ID:
IYS2022_trawl_catch$catch_id[duplicated(IYS2022_trawl_catch$catch_id)] # should print character(0)

# Save catch data:
write_csv(IYS2022_trawl_catch, here("output_datasets", "IYS2022_trawl_catch.csv"))
```

## Specimen Data

Now let's join the overall specimen data from these vessels into a specific data frame as well. 

Note: Evgeny indicated it would be good to have GSI and age data in the specimen tables once they are available


```{r overall specimen, eval = FALSE}
NW_specimen <- read_excel(here("input_datasets", "IYS2022_NW_Data.xlsx"), sheet = "Specimen_Info")
TINRO_specimen <- read_excel(here("input_datasets", "IYS2022_TINRO_Data.xlsx"), sheet = "6. SPECIMEN INFO")
Shimada_specimen <- read_excel(here("input_datasets", "IYS2022_Shimada_Data.xlsx"), sheet = "6. SPECIMEN INFO")
Franklin_specimen <- read_excel(here("input_datasets", "IYS2022_Franklin_Data.xlsx"), sheet = "5. SPECIMEN INFO")
GoA2019_specimen <- read_excel(here("JuvSalmon_2019-01_Specimens_v21.01b_SUBMITTED_COPY (2).xlsx"),
                            sheet = "SPECIMEN_FINAL")

#TODO: Integrate age data
#TODO: Integrate genetic stock ID data
```


Cleaning NW specimen column names:

```{r NW specimen clean, eval = FALSE}
NW_specimen <- NW_specimen %>%
  dplyr::rename(Station_Event_ID = `Station Event ID`,
                Catch_ID = `Catch ID`,
                Specimen_ID = `Specimen ID`,
                Specimen_Length = Length,
                Specimen_Weight = Weight) %>%
  rename_with(tolower)
```

Cleaning Franklin, TINRO, and Shimada specimen column names:

```{r TINRO, Shimada, Frankin, eval = FALSE}
TINRO_specimen <- TINRO_specimen %>% rename_with(tolower)
Shimada_specimen <- Shimada_specimen %>% rename_with(tolower)

Franklin_specimen <- Franklin_specimen %>% rename_with(tolower)
Franklin_specimen$specimen_length <- as.numeric(Franklin_specimen$specimen_length)
Franklin_specimen$specimen_weight <- as.numeric(Franklin_specimen$specimen_weight)
```

Clean the GOA2019 Trawl specimen data to integrate with 2022 data:

```{r GOA2019 specimen clean, eval = FALSE}
GoA2019_specimen <- GoA2019_specimen %>%
  mutate(cruise_name = "IYS2022",
         Vessel_name_abbr = "Professor Kaganovskiy", 
         Zone = " ",
         Event_Type = "Trawl",
         data_type = "specimen",
         Scientific_Name = paste(genus, species, sep = " ")) %>%
  dplyr::rename(Station = TOW_NUMBER,
                common_name = `common name`) %>%
  select(Station, common_name, LENGTH, SEX_CODE, `WEIGHT - TOTAL`, cruise_name, Vessel_name_abbr, Zone, Scientific_Name, Event_Type,
         data_type)

GoA2019_specimen <- GoA2019_specimen %>%
  mutate(Station_Event_ID = paste(cruise_name, Vessel_name_abbr, Station, Event_Type, sep = "-"))

# We want to compare the catch and the specimen data tables by joining them by Station_Event_ID and Scientific_Name. Therefore, we have to ensure that the spelling of Scientific_Names at least matches between these data frames (regardless of whether it is accuratedly represented in WORMS)
specimen_unique <- unique(GoA2019_specimen$Scientific_Name)
catch_unique <- unique(GoA2019_catch$Scientific_Name)

setdiff(specimen_unique, catch_unique)

# You can notice that in the specimen data, species names' are often followed by Russian (e.g. полов.). We need to remove these as otherwise we can't properly connect the catch to the specimen data. 
GoA2019_specimen$Scientific_Name <- gsub("[()]", "", GoA2019_specimen$Scientific_Name)
GoA2019_specimen$Scientific_Name <- gsub(" неполов.", "", GoA2019_specimen$Scientific_Name)
GoA2019_specimen$Scientific_Name <- gsub(" сегол.", "", GoA2019_specimen$Scientific_Name)
GoA2019_specimen$Scientific_Name <- gsub(" полов.", "", GoA2019_specimen$Scientific_Name)
GoA2019_specimen$Scientific_Name <- gsub(" мол.", "", GoA2019_specimen$Scientific_Name)

# Make sure to remove the  мол. from the catch data as well. 
GoA2019_catch$Scientific_Name <- gsub("[()]", "", GoA2019_catch$Scientific_Name)
GoA2019_catch$Scientific_Name <- gsub(" мол.", "", GoA2019_catch$Scientific_Name)
GoA2019_catch$Scientific_Name <- gsub("Phacellophora camtshchatica", "Phacellophora camtschatica", GoA2019_catch$Scientific_Name)

# Left join to the GoA2019_catch data table so that we can create the specimen_IDs
merge <- left_join(GoA2019_catch, GoA2019_specimen, by = c("Station_Event_ID", "Scientific_Name"))
merge <- merge %>% group_by(Catch_ID) %>% 
  mutate(Specimen_ID = paste(Catch_ID, row_number(), sep = "-")) %>%
  ungroup()

GOA2019_specimen_tab <- merge %>% filter(data_type == "specimen") %>%
  dplyr::rename(Species_Recorded = Species_recorded,
                Specimen_Length = LENGTH,
                Specimen_Weight = `WEIGHT - TOTAL`,
                Sex = SEX_CODE) %>%
  select(Station_Event_ID, Catch_ID, Specimen_ID, Species_Recorded, Scientific_Name, Lifestage, Specimen_Length,
         Specimen_Weight, Sex)

```

Join the specimen data rows. 

```{r specimen, eval = FALSE}
# Check for differences in column header names between those two data frames:
janitor::compare_df_cols(NW_specimen, TINRO_specimen, Shimada_specimen, Franklin_specimen)

# Bind rows and save: 
IYS2022_trawl_specimen <- bind_rows(TINRO_specimen, NW_specimen, Shimada_specimen, Franklin_specimen)

#TODO: Get corrections for duplicate specimen IDs
# Confirm no duplicates in Specimen_ID:
IYS2022_trawl_specimen$specimen_id[duplicated(IYS2022_trawl_specimen$specimen_id)] # should print character(0)

# Save specimen data:
write_csv(IYS2022_trawl_specimen, here("output_datasets", "IYS2022_trawl_specimen.csv"))
```

Next, integrate the CTD data (please note, we do not have CTD/Rosette data from the NW Explorer):

# CTD

```{r 2022 TINRO CTD, eval = FALSE}
TINRO_CTD <- read_excel(here("input_datasets", "IYS2022_TINRO_Data.xlsx"), sheet = "7. CTD INFO") |> 
  rename(station_event_ID = Station_Event_ID,
         instrument_type = Instrument_Type,
         instrument_model = Instrument_Model,
         comments = Comments,
         sampling_depth_dbar = Sampling_Depth_Dbar,
         sea_water_chl_a_concentration = sea_water_chl_concentration
         ) |> 
  mutate(comments = as.character(comments))
```

```{r 2019 Kaganovsky CTD}
 
ctd_2019_data <- IYS_2019_CTD |> 
   select(station_event_ID, instrument_type:sea_water_BOD5) |> 
  mutate(sea_water_BOD5 = as.numeric(sea_water_BOD5))

```

```{r Overall CTD}
#TODO Include 2020 CTD data
#TODO check all units are the same
janitor::compare_df_cols(TINRO_CTD, ctd_2019_data)
IYS2022_CTD <- bind_rows(TINRO_CTD, ctd_2019_data) |> 
  select(station_event_ID:sampling_depth_dbar, sampling_depth_meters,
         sea_water_temperature:sea_water_dissolvedO2_sat,
         sea_water_concentration_of_oxygen, sea_water_pH:comments)

# QC value ranges for unit issues
IYS2022_CTD |> 
  group_by(vessel)

write_csv(IYS2022_CTD, here("output_datasets", "IYS2022_CTD.csv"))
```

# Biogeochemistry Data

Include Biogeochemistry data

```{r}
#TODO combine rosette and CTD event IDs where possible
#TODO creat 'bottle file' from rosette and CTD data (probably just add ctd data to rosette table at appropriate depths)
#TODO add 2019 POM data
#TODO add 2019 Chl and  Phaeopigment data
#TODO add 2019 Nutrient, Oxygen data
#TODO add 2020 Nutrient data
#TODO add 2022 Nutrient and oxygend data
```


# QC

```{r QC relations}
library(dm)

dm_no_keys <- dm(IYS2022_trawl_catch, IYS2022_trawl_event, IYS2022_trawl_specimen, IYS2022_CTD)

# add primary keys
only_pk <- dm_no_keys %>% 
  dm_add_pk(IYS2022_trawl_catch, Catch_ID) %>% 
  dm_add_pk(IYS2022_trawl_event, Station_Event_ID) %>% 
  dm_add_pk(IYS2022_trawl_specimen, Specimen_ID)
  
only_pk %>% dm_examine_constraints() # checks for duplicates in PK

# add foreign keys
dm <- only_pk %>% 
  dm_add_fk(IYS2022_CTD, Station_Event_ID, IYS2022_trawl_event) %>% 
  dm_add_fk(IYS2022_trawl_specimen, Catch_ID, IYS2022_trawl_catch) %>% 
  dm_add_fk(IYS2022_trawl_catch, Station_Event_ID, IYS2022_trawl_event)

dm %>% dm_examine_constraints() # checks that foreign keys all have a matching primary key in  the parent table

# manually  export the drawing from the viewer pane to figs to update the data model image
dm_draw(dm)
```

```{r Data Dictionary}
#TODO Decide to create a data dictionary, or use secondary columns to define units, or include units in column name
```

Combine all data frames into a single .xlsx workbook:

```{r final_join, eval = FALSE}
out <- list("Sampling Event Info" = IYS2022_events, "Overall_Catch_Data" = IYS2022_trawl_catch, "Overall_Specimen_Data" = IYS2022_trawl_specimen,
            "Overall_CTD_Data" = IYS2022_CTD)
writexl::write_xlsx(out, "master.xlsx")
```

Create polygon coordinates for all events

```{r polygon coords}

polygon_coords <- function(df) {
  df <- df %>% tidyr::drop_na(lat, lon) %>% 
    dplyr::mutate(lon = dplyr::if_else(lon < 0, 360 + lon, lon))
  ch <- chull(df)
  coords <- df[c(ch, ch[1]), ]
  coords <- paste(coords$lat, coords$lon, sep = ",", collapse = " ")
  coords
}

df <- IYS2022_trawl_event %>% 
  select(lat = Latitude_Start_DecDeg, lon = Longitude_Start_DecDeg) %>% 
  filter(lat != 0 | lon != 0)

#copy output from console into metadata intake form polygon coordinates  
polygon_coords(df)

max(IYS2022_trawl_event$Maximum_Sampling_Depth_Meters)

```

```{r Stations list}
# This can be re-written later. I produced this stations plot list for Tetjana Ross
stations <- IYS2022_trawl_event |> 
  filter(event_type %in% c("CanTrawl", "Trawl")) |> 
  distinct(vessel_name_abbr, year, month, day, latitude_start_decdeg, longitude_start_decdeg) |> 
  rename(Lat = latitude_start_decdeg,
         Long = longitude_start_decdeg,
         vessel = vessel_name_abbr)

Franklin_stations <- Franklin_event |> 
  filter(Event_Type == "Trawl") |> 
  mutate(year = year(Time_Start_UTC),
         month = month(Time_Start_UTC),
         day = day(Time_Start_UTC)) |> 
  select(vessel = Vessel_Name_Abbr, year, month, day,
         Lat = Latitude_Start_DecDeg,
         Long = Longitude_Start_DecDeg)
  

stations_2019 <- GoA2019_event |> 
  mutate(year = year(EVENT_DATE),
         month = month(EVENT_DATE),
         day = day(EVENT_DATE)) |> 
  select(year, month, day, Lat = START_LATITUDE_DD, Long = longitude) |> 
  distinct()|> 
  mutate(vessel = "Kaganovksy")

stations_2020 <- GoA2020_event |> 
  mutate(year = year(EVENT_DATE),
         month = month(EVENT_DATE),
         day = day(EVENT_DATE)) |> 
  select(year, month, day, Lat = START_LAT_DECDEGREE, Long = START_LONG_DECDEGREE) |> 
  distinct() |> 
  mutate(vessel = "Pacific Legacy")


stations <- bind_rows(stations, Franklin_stations)

write_csv(stations, "stations.csv")
```

